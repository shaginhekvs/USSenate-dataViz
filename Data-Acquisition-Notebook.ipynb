{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "data_folder = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"\"\n",
    "\n",
    "with open('api_key.txt') as f:\n",
    "    API_KEY = f.read()\n",
    "\n",
    "HEADERS = {\"X-Api-Key\": API_KEY}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "create_folder(data_folder)\n",
    "create_folder(data_folder + 'commitees')\n",
    "create_folder(data_folder + 'senate_members')\n",
    "create_folder(data_folder + 'votes')\n",
    "create_folder(data_folder + 'lobby')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request config\n",
    "req_str = \"https://api.propublica.org/congress/v1/senate/votes/recent.json?offset={offset}\"\n",
    "\n",
    "res = requests.get(req_str.format(offset=460), headers = HEADERS)\n",
    "\n",
    "print(json.dumps(res.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching senate members (congress 80 to 115)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = \"https://api.propublica.org/congress/v1/{congress}/senate/members.json\"\n",
    "\n",
    "for i in range(80, 115 + 1):\n",
    "    results = requests.get(url = u.format(congress=i), headers=HEADERS)\n",
    "    df = pd.io.json.json_normalize(results.json()['results'][0]['members'])\n",
    "    df.to_csv(\"data/senate_members/senate_members_{congress}.csv\".format(congress=i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching vote data from senate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request config\n",
    "u = \"https://api.propublica.org/congress/v1/senate/votes/recent.json?offset={offset}\"\n",
    "\n",
    "votes_list = []\n",
    "data_available = True\n",
    "request_offset = 0\n",
    "\n",
    "while data_available :\n",
    "    res = requests.get(url = u.format(offset = request_offset), headers = HEADERS)\n",
    "    if('results' in res.json()):\n",
    "        data_available = int(res.json()['results']['num_results']) > 0\n",
    "\n",
    "        if data_available:\n",
    "            votes = res.json()['results']['votes']\n",
    "            votes_list.append(pd.io.json.json_normalize(votes, record_prefix=True))\n",
    "    else:\n",
    "        print(str(request_offset) + ' - Error: ' + res.json()['error'])\n",
    "    request_offset += 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(votes_list,sort=True)\n",
    "df.to_csv(data_folder + \"votes/votes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Commitees from senate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request config\n",
    "u = \"https://api.propublica.org/congress/v1/{congress}/senate/committees.json\"\n",
    "\n",
    "for i in range(114, 115 + 1):\n",
    "    create_folder(data_folder + 'commitees/commitees_' + str(i))\n",
    "    results_commitee = requests.get(url = u.format(congress=i), headers=HEADERS)\n",
    "    df = pd.io.json.json_normalize(results_commitee.json()['results'][0]['committees'])\n",
    "    df_list = []\n",
    "    for commitee_id in df['id']:\n",
    "        subcommitee_id = df[df['id'] == commitee_id]['subcommittees']\n",
    "\n",
    "        for subcommitee in subcommitee_id.values[0]:\n",
    "            results_sub = requests.get(url = subcommitee['api_uri'], headers=HEADERS)\n",
    "            if 'results' in results_sub.json():\n",
    "                df_sub = pd.io.json.json_normalize(results_sub.json()['results'][0]['current_members'])\n",
    "                df_sub['subcomitee'] = subcommitee['id']\n",
    "                df_sub['comitee'] = commitee_id\n",
    "                df_list.append(df_sub)\n",
    "\n",
    "    if len(df_list) > 0:\n",
    "        df_merged = pd.concat(df_list)\n",
    "        df_merged.to_csv(data_folder + 'commitees/commitees_{congress}/members.csv'.format(congress = i,commitee_id = elem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Lobbying from senate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.compile(\"\\((.*)\\\"([\\w ]+)\\\"(.*)\\)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request config\n",
    "u = \"https://api.propublica.org/congress/v1/lobbying/latest.json?offset={offset}\"\n",
    "\n",
    "votes_list = []\n",
    "data_available = True\n",
    "request_offset = 0\n",
    "\n",
    "while data_available :\n",
    "    res = requests.get(url = u.format(offset = request_offset), headers = HEADERS)\n",
    "    j  = res.text.replace(\"\\\\\\\"\",\"\").replace(\"\\\\\",\"\").replace(\"\\\")\", \")\").replace(\"(\\\"\", \"(\")\n",
    "\n",
    "    try:\n",
    "        res = json.loads(j)       \n",
    "        if('results' in res):\n",
    "            #print(request_offset)\n",
    "            data_available = int(res['results'][0]['num_results']) > 0\n",
    "\n",
    "            if data_available:\n",
    "                votes = res['results'][0]['lobbying_representations']\n",
    "                votes_list.append(pd.io.json.json_normalize(votes, record_prefix=True))\n",
    "        else:\n",
    "            print(str(request_offset) + ' - Error: ' + res['error'])\n",
    "    except:\n",
    "        print(str(request_offset) + ' - Error: Json File badly encoded')\n",
    "    request_offset += 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(votes_list,sort=True)\n",
    "df.to_csv(data_folder + \"lobby/lobby.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Getting voting position by member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_senators = pd.DataFrame()\n",
    "\n",
    "for i in range (115, 80 - 1, -1):\n",
    "    df = pd.read_csv(\"data/senate_members/senate_members_{congress}.csv\".format(congress = i))\n",
    "    df['congress'] = i\n",
    "    raw_senators = pd.concat([raw_senators, df], sort=False)\n",
    "    \n",
    "senators_id = raw_senators['id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = \"https://api.propublica.org/congress/v1/members/{member_id}/votes.json?offset={offset}\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "completed_ids = os.listdir(\"data/votes\")\n",
    "\n",
    "for senator_id in senators_id[2::4]:\n",
    "\n",
    "    if \"votes_{id}.csv\".format(id=senator_id) in completed_ids:\n",
    "        continue\n",
    "        \n",
    "    error_raised = False\n",
    "    votes_list = []\n",
    "    data_available = True\n",
    "    request_offset = 0\n",
    "\n",
    "    while data_available :\n",
    "        res = requests.get(url = u.format(member_id = senator_id, offset = request_offset), headers = HEADERS)\n",
    "        jObj = json.loads(res.text.replace('\\n', ' '))\n",
    "                \n",
    "        #print(res.text)\n",
    "        if(res.status_code == 200):\n",
    "            data_available = int(jObj['results'][0]['num_results']) > 0\n",
    "\n",
    "            if data_available:\n",
    "                print(str(senator_id) + \" offset: \" + str(request_offset), end='\\r')\n",
    "                votes = jObj['results'][0]['votes']\n",
    "                votes_list.append(pd.io.json.json_normalize(votes, record_prefix=True))\n",
    "                \n",
    "        else:\n",
    "            print(str(res.status_code))\n",
    "            error_raised = True\n",
    "            break\n",
    "        \n",
    "        request_offset += 20\n",
    "        \n",
    "    if not error_raised and len(votes_list) > 0:\n",
    "        df = pd.concat(votes_list,sort=False)\n",
    "        df.to_csv(data_folder + \"votes/votes_{id}.csv\".format(id=senator_id), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
